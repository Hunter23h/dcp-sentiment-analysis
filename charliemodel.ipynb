{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hunte\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tf2onnx\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_parsed_dataset.csv', usecols=[2,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['rt','http', 'https:', 'http:']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hunte\\AppData\\Local\\Temp/ipykernel_20096/2922597320.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Text'][index]=re.sub('@[^\\s]+','',df['Text'][index])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i read them in context no change in meaning...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>now you idiots claim that people who tried to...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call me sexist  but when i go to an auto pla...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wrong  isis follows the example of mohammed a...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mkr no no no no no no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16846</th>\n",
       "      <td>feeling so sorry for the girls  they should be...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16847</th>\n",
       "      <td>mkr  pretty good dishes we re happy with    o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16848</th>\n",
       "      <td>deconstructed lemon ta     can we please go ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16849</th>\n",
       "      <td>you are too stupid to talk to  blocked</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16850</th>\n",
       "      <td>and before you protest that you re  not  mad  ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16848 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text  Label\n",
       "0         i read them in context no change in meaning...    0.0\n",
       "1       now you idiots claim that people who tried to...    0.0\n",
       "2        call me sexist  but when i go to an auto pla...    1.0\n",
       "3       wrong  isis follows the example of mohammed a...    1.0\n",
       "4                                  mkr no no no no no no    0.0\n",
       "...                                                  ...    ...\n",
       "16846  feeling so sorry for the girls  they should be...    0.0\n",
       "16847   mkr  pretty good dishes we re happy with    o...    0.0\n",
       "16848    deconstructed lemon ta     can we please go ...    0.0\n",
       "16849            you are too stupid to talk to  blocked     0.0\n",
       "16850  and before you protest that you re  not  mad  ...    0.0\n",
       "\n",
       "[16848 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={'oh_label': 'Label'})\n",
    "for index in df.index:\n",
    "    try:\n",
    "        df['Text'][index]=re.sub('@[^\\s]+','',df['Text'][index])\n",
    "    except:\n",
    "        pass\n",
    "df.replace(to_replace=\"[^a-zA-Z]\", value=\" \", regex=True, inplace=True)\n",
    "df['Text'] = df['Text'].str.lower()\n",
    "for i in stopwords:\n",
    "    df['Text'] = df['Text'].str.replace(i, '')\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(subset=['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.sample(frac=0.8,random_state=200)\n",
    "test=df.drop(train.index).sample(frac=1.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train['Text'].astype('str')\n",
    "train_label = train['Label']\n",
    "test_data = test['Text'].astype('str')\n",
    "test_label = test['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=10000, oov_token='<UNK>')\n",
    "tokenizer.fit_on_texts(train_data)\n",
    "tokenizer.fit_on_texts(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen=50\n",
    "def get_sequences(tokenizer, tokened):\n",
    "    sequences = tokenizer.texts_to_sequences(tokened)\n",
    "    padded = pad_sequences(sequences, truncating = 'post', padding='post', maxlen=maxlen)\n",
    "    return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_padded = get_sequences(tokenizer, train_data)\n",
    "test_data_padded = get_sequences(tokenizer, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "tf.keras.layers.Embedding(10000,16,input_length=maxlen),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "tf.keras.layers.Dense(6, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "     loss='sparse_categorical_crossentropy',\n",
    "     optimizer='adam',\n",
    "     metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422/422 [==============================] - 20s 32ms/step - loss: 0.5848 - accuracy: 0.7486\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_padded,\n",
    "    train_label,\n",
    "    epochs=1, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/106 [==============================] - 3s 10ms/step - loss: 0.4092 - accuracy: 0.8220\n",
      "Loss:  0.409199595451355\n",
      "Accuracy:  0.8219584822654724\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_data_padded, test_label)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_signature = [tf.TensorSpec([None, None], tf.int32, name='x')]\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(model, input_signature, opset=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx.save(onnx_model, \"charlie.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"charlie.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_sess = ort.InferenceSession('model.onnx')\n",
    "outputs = ort_sess.run(None, {'x': test_data_padded})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9.39577401e-01, 5.99975474e-02, 1.30807282e-04, 5.77332939e-05,\n",
       "        6.79429359e-05, 1.68567727e-04],\n",
       "       [9.32920158e-01, 6.66228384e-02, 1.45630649e-04, 6.37666744e-05,\n",
       "        7.32636618e-05, 1.74334797e-04],\n",
       "       [8.79249454e-01, 1.20100670e-01, 2.54144717e-04, 1.07261643e-04,\n",
       "        1.05611092e-04, 1.82828866e-04],\n",
       "       ...,\n",
       "       [8.45851243e-01, 1.53399035e-01, 3.12716118e-04, 1.30782035e-04,\n",
       "        1.20025965e-04, 1.86190300e-04],\n",
       "       [9.42601487e-02, 9.03148949e-01, 1.04690541e-03, 6.77421398e-04,\n",
       "        4.19969758e-04, 4.46591468e-04],\n",
       "       [9.35477793e-01, 6.40775710e-02, 1.40489428e-04, 6.12457734e-05,\n",
       "        7.13842237e-05, 1.71494845e-04]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b7810888083ee3ab3f8e624f45a5197bc5edfadd1b0a4293fd6cf3d4aaf542e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
